{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#library\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#Common Model Helpers\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "#Visualization\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "# Importing Models\n",
    "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Importing other tools\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import confusion_matrix, classification_report, make_scorer\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_recall_curve\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "# from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import KFold, ShuffleSplit, StratifiedKFold\n",
    "import warnings\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# import plotly.express as px\n",
    "import itertools\n",
    "from mlflow import sklearn\n",
    "import mlflow.sklearn\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading local functions\n",
    "from src.features.build_features import prep_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:\\mlops_plugin\\src\\data\\data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the mlflow local server - Ideally set this server on remote server(Aws, Azure or GCP - for experiments - free tier will work)\n",
    "# local server setup will not store artificate( models & data files) - you need remote server or database for that\n",
    "# refer here : https://www.mlflow.org/docs/latest/quickstart.html\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"http://kubernetes.docker.internal:5000/\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"Pre_Process\"\n",
    "mlflow.set_experiment(exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = prep_process(data)\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>FareBand</th>\n",
       "      <th>AgeBand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex  Embarked  Title  IsAlone  FareBand  AgeBand\n",
       "759       1    1         0      5        1         3        2\n",
       "378       3    0         1      1        1         0        0\n",
       "696       3    0         0      1        1         1        3\n",
       "222       3    0         0      1        1         1        3\n",
       "107       3    0         0      1        1         0        1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up modeling experiment on MLFlow\n",
    "exp_name = \"Modeling\"\n",
    "mlflow.set_experiment(exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_params = {\n",
    "  'seed':123,\n",
    "  'folds': 10,\n",
    "  'test_size': 0.3,\n",
    "  'train_size': 0.7,\n",
    "  'n_jobs':-1,\n",
    "  'verbose':3,\n",
    "  'scoring':'f1',   \n",
    "  'Split_type': 'ShuffleSplit',\n",
    "  'warning': warnings.filterwarnings('ignore'),\n",
    "  'normalize': True\n",
    "}\n",
    "\n",
    "base_model = {\n",
    "    'AdaBoostClassifier': AdaBoostClassifier(),\n",
    "    'BaggingClassifier':BaggingClassifier(),\n",
    "    'ExtraTreesClassifier':ExtraTreesClassifier(),\n",
    "    'GradientBoostingClassifier':GradientBoostingClassifier(),\n",
    "    'RandomForestClassifier':RandomForestClassifier(),\n",
    "    'GaussianProcessClassifier':gaussian_process.GaussianProcessClassifier(),\n",
    "    'LogisticRegressionCV':linear_model.LogisticRegressionCV(),\n",
    "    'PassiveAggressiveClassifier':linear_model.PassiveAggressiveClassifier(),\n",
    "    'RidgeClassifierCV':linear_model.RidgeClassifierCV(),\n",
    "    'SGDClassifier':linear_model.SGDClassifier(),\n",
    "    'Perceptron':linear_model.Perceptron(),\n",
    "    'BernoulliNB':naive_bayes.BernoulliNB(),\n",
    "    'GaussianNB':naive_bayes.GaussianNB(),\n",
    "    'KNeighborsClassifier':KNeighborsClassifier(),\n",
    "    'SVC':svm.SVC(probability=True),\n",
    "    'NuSVC':svm.NuSVC(probability=True),\n",
    "    'LinearSVC':svm.LinearSVC(),\n",
    "    'DecisionTreeClassifier':DecisionTreeClassifier(),\n",
    "    'LinearDiscriminantAnalysis':discriminant_analysis.LinearDiscriminantAnalysis(),\n",
    "    'QuadraticDiscriminantAnalysis':discriminant_analysis.QuadraticDiscriminantAnalysis(),\n",
    "    'XGBClassifier':XGBClassifier(),\n",
    "    'LGBMClassifier':LGBMClassifier()   \n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModellingHelper:\n",
    "\n",
    "    def __init__(self, std_param, base_model):\n",
    "        \n",
    "        self.std_param = std_param\n",
    "        if self.std_param['Split_type'] == 'ShuffleSplit':\n",
    "          self.cross_val = model_selection.ShuffleSplit(n_splits = self.std_param['folds'], test_size = self.std_param['test_size'], train_size = self.std_param['train_size'], random_state = self.std_param['seed'] )\n",
    "\n",
    "        self.base_model = base_model\n",
    "        self.base_model_output = {}\n",
    "        self.feature_importance_df_sorted = pd.DataFrame()\n",
    "        self.important_col =[]\n",
    "\n",
    "        self.scoring = { 'accuracy' : make_scorer(metrics.accuracy_score),\n",
    "                  'precision' : make_scorer(metrics.precision_score),\n",
    "                  'recall' : make_scorer(metrics.recall_score),\n",
    "                  'f1_score' : make_scorer(metrics.f1_score),\n",
    "                  'average_precision': make_scorer(metrics.average_precision_score),\n",
    "                  'balanced_accuracy': make_scorer(metrics.balanced_accuracy_score),\n",
    "                  'hamming_loss':make_scorer(metrics.hamming_loss),\n",
    "                  'jaccard_score': make_scorer(metrics.jaccard_score),\n",
    "                  'log_loss': make_scorer(metrics.log_loss),\n",
    "                  'roc_auc_score':make_scorer(metrics.roc_auc_score),\n",
    "                  'zero_one_loss':make_scorer(metrics.zero_one_loss,normalize=False)\n",
    "                  }\n",
    "\n",
    "\n",
    "        self.scores_list = []\n",
    "        self.feature_importance = {}\n",
    "        self.FeatureImportanceAlgo = ['DecisionTreeClassifier','RandomForestClassifier','ExtraTreesClassifier','GradientBoostingClassifier','AdaBoostClassifier']\n",
    "\n",
    "    def getScoreDictionary(self, base_model_output,modelname, basemodel_scores, score_type):\n",
    "      self.base_model_output[modelname]['Time'] = basemodel_scores['fit_time'].mean()\n",
    "      self.base_model_output[modelname]['%s_accuracy' %score_type ] =  basemodel_scores['%s_accuracy' %score_type].mean()\n",
    "      self.base_model_output[modelname]['%s_precision' %score_type ] =  basemodel_scores['%s_precision' %score_type].mean()\n",
    "      self.base_model_output[modelname]['%s_recall' %score_type ] =  basemodel_scores['%s_recall' %score_type].mean()\n",
    "      self.base_model_output[modelname]['%s_f1_score' %score_type ] =  basemodel_scores['%s_f1_score' %score_type].mean()\n",
    "      self.base_model_output[modelname]['%s_average_precision' %score_type ] =  basemodel_scores['%s_average_precision' %score_type].mean()\n",
    "      self.base_model_output[modelname]['%s_balanced_accuracy' %score_type ] =  basemodel_scores['%s_balanced_accuracy' %score_type].mean()\n",
    "      self.base_model_output[modelname]['%s_hamming_loss' %score_type ] =  basemodel_scores['%s_hamming_loss' %score_type].mean()\n",
    "      self.base_model_output[modelname]['%s_jaccard_score' %score_type ] =  basemodel_scores['%s_jaccard_score' %score_type].mean()\n",
    "      self.base_model_output[modelname]['%s_log_loss' %score_type ] =  basemodel_scores['%s_log_loss' %score_type].mean()\n",
    "      self.base_model_output[modelname]['%s_roc_auc_score' %score_type ] =  basemodel_scores['%s_roc_auc_score' %score_type].mean()\n",
    "      self.base_model_output[modelname]['%s_zero_one_loss' %score_type ] =  basemodel_scores['%s_zero_one_loss' %score_type].mean()\n",
    "\n",
    "      return None\n",
    "\n",
    "    def ModelLoop(self,X, y, score_type=None):\n",
    "        \n",
    "      for key, eachModel in self.base_model.items():\n",
    "          with mlflow.start_run(nested=True):\n",
    "              basemodel_scores = model_selection.cross_validate(eachModel, X,y, cv  = self.cross_val,return_train_score=True,scoring=self.scoring, pre_dispatch=\"2*n_jobs\",return_estimator=True)\n",
    "              modelname = eachModel.__class__.__name__\n",
    "              self.base_model_output[modelname] = {}\n",
    "              self.getScoreDictionary(self.base_model_output,modelname, basemodel_scores, 'train')\n",
    "              self.getScoreDictionary(self.base_model_output,modelname, basemodel_scores, 'test')\n",
    "              self.scores_list.append(basemodel_scores)\n",
    "              mlflow.log_param(\"Model\", modelname)\n",
    "              mlflow.log_param(\"time\", self.base_model_output[modelname]['Time'])\n",
    "              score_type_mlflow = 'test'\n",
    "              mlflow.log_metric(\"accuracy\", basemodel_scores['%s_accuracy' %score_type_mlflow].mean())\n",
    "              mlflow.log_metric(\"Precision\", basemodel_scores['%s_precision' %score_type_mlflow].mean())\n",
    "              mlflow.log_metric(\"Recall\", basemodel_scores['%s_recall' %score_type_mlflow].mean())\n",
    "              mlflow.log_metric(\"F1\", basemodel_scores['%s_f1_score' %score_type_mlflow].mean())\n",
    "              model = eachModel.fit(X,y)\n",
    "              modelpath = \"C://mlops_plugin//models//model-%s%f\" % (modelname,random.random())\n",
    "              mlflow.sklearn.save_model(model, modelpath)\n",
    "\n",
    "              if eachModel.__class__.__name__ in self.FeatureImportanceAlgo:\n",
    "                eachModel.fit(X,y)\n",
    "                self.feature_importance[eachModel.__class__.__name__]= eachModel.feature_importances_\n",
    "            \n",
    "\n",
    "    def runBaseLineModel(self, X, y, score_type=None, auto_feature_eng = None , top_feature = None ):\n",
    "      if top_feature:\n",
    "        print (\"Building model with only %s important feature\" % top_feature)\n",
    "        #Initial Model Loop to extract top feature\n",
    "        self.ModelLoop(X, y, score_type)\n",
    "        imp_df = self.getFeatureImportance(self.getFeatureImportanceDF(X, self.feature_importance))\n",
    "        important_col = list(imp_df[:top_feature].index)\n",
    "        self.important_col = important_col\n",
    "        X = X[important_col]\n",
    "        self.ModelLoop(X, y,score_type)\n",
    "        # tracking \n",
    "\n",
    "      else:\n",
    "        print (\"Building model without any important feature\")\n",
    "        self.ModelLoop(X, y,score_type)\n",
    "\n",
    "    def getFeatureImportanceDF(self, X, feature_importance_dict, important_col=None):\n",
    "      if important_col:\n",
    "        feature_names = important_col\n",
    "        feat_imp_df = pd.DataFrame.from_dict(feature_importance_dict)\n",
    "        feat_imp_df.index = feature_names\n",
    "        return feat_imp_df\n",
    "      else:\n",
    "        feature_names = X.columns\n",
    "        feat_imp_df = pd.DataFrame.from_dict(feature_importance_dict)\n",
    "        feat_imp_df.index = feature_names\n",
    "        return feat_imp_df\n",
    "\n",
    "    def getFeatureImportance(self,feat_imp_df):\n",
    "      mms = MinMaxScaler()\n",
    "      # scaling to MinMax Scale\n",
    "      scaled_fi = pd.DataFrame(data=mms.fit_transform(feat_imp_df),columns=feat_imp_df.columns,index=feat_imp_df.index)\n",
    "      # Adding all values of importance to get single socre\n",
    "      scaled_fi['SumofImp'] = scaled_fi.sum(axis=1)\n",
    "      # print(scaled_fi.head())\n",
    "      ordered_ranking = scaled_fi.sort_values('SumofImp', ascending=False)\n",
    "      return ordered_ranking\n",
    "\n",
    "\n",
    "    def getFeatureImportanceGraph(self,ordered_feature_importance_df):\n",
    "      self.feature_importance_df_sorted.append(ordered_feature_importance_df)\n",
    "      fig, ax = plt.subplots(figsize=(10,7), dpi=80)\n",
    "      sns.barplot(data=ordered_feature_importance_df, y=ordered_feature_importance_df.index, x='SumofImp', palette='magma')\n",
    "      ax.spines['right'].set_visible(False)\n",
    "      ax.spines['top'].set_visible(False)\n",
    "      ax.spines['bottom'].set_visible(False)\n",
    "      ax.xaxis.set_visible(False)\n",
    "      ax.grid(False)\n",
    "      ax.set_title('Aggregated Feature Importances for Models');\n",
    "      return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelObject = BaseModellingHelper(basic_params,base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model with only 5 important feature\n",
      "Wall time: 1min 54s\n"
     ]
    }
   ],
   "source": [
    "%time ModelObject.runBaseLineModel(x_train,y_train,score_type='test',top_feature=5)\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dumping results in pickle for streamlit Dashbaord\n",
    "import pickle\n",
    "pickle_out = open(\"C:\\mlops_plugin\\src\\models\\pickle_temp\\ModelBaseObject.pickle\",\"wb\")\n",
    "pickle.dump(ModelObject.base_model_output, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dumping important feature df to pickle\n",
    "import pickle\n",
    "pickle_out = open(\"C:\\mlops_plugin\\src\\models\\pickle_temp\\ModelBaseObject_featureimpdf.pickle\",\"wb\")\n",
    "imprtant_feature_df = ModelObject.getFeatureImportance(ModelObject.getFeatureImportanceDF(x_train, ModelObject.feature_importance, ModelObject.important_col))\n",
    "pickle.dump(imprtant_feature_df, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Time': 0.06555182933807373,\n",
       " 'train_accuracy': 0.8481927710843372,\n",
       " 'train_precision': 0.8279109550199907,\n",
       " 'train_recall': 0.7581919438499525,\n",
       " 'train_f1_score': 0.7901486145107256,\n",
       " 'train_average_precision': 0.7176756355740715,\n",
       " 'train_balanced_accuracy': 0.8300568577103077,\n",
       " 'train_hamming_loss': 0.15180722891566267,\n",
       " 'train_jaccard_score': 0.6532013719762055,\n",
       " 'train_log_loss': 5.243284584854182,\n",
       " 'train_roc_auc_score': 0.8300568577103077,\n",
       " 'train_zero_one_loss': 75.6,\n",
       " 'test_accuracy': 0.794392523364486,\n",
       " 'test_precision': 0.7545932715898391,\n",
       " 'test_recall': 0.6693334952903214,\n",
       " 'test_f1_score': 0.7057037196913832,\n",
       " 'test_average_precision': 0.6261328713512292,\n",
       " 'test_balanced_accuracy': 0.7699038195664563,\n",
       " 'test_hamming_loss': 0.20560747663551404,\n",
       " 'test_jaccard_score': 0.5456602160703631,\n",
       " 'test_log_loss': 7.101496421919821,\n",
       " 'test_roc_auc_score': 0.7699038195664564,\n",
       " 'test_zero_one_loss': 44.0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelObject.base_model_output['BaggingClassifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! cd C:\\mlops_plugin\\src\\visualization\n",
    "#! streamlit run baseline_model.py\n",
    "# On another tab - \n",
    "#! cd C:\\mlops_plugin\\src\\visualization\n",
    "#! streamlit run model_interpretation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production API \n",
    "{\n",
    "  \"Pclass\": 3,\n",
    "  \"Sex\": 1,\n",
    "  \"Embarked\": 1,\n",
    "  \"Title\": 2,\n",
    "  \"IsAlone\": 1,\n",
    "  \"FareBand\": 0,\n",
    "  \"AgeBand\": 0\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.to_csv(\"C:/mlops_plugin/src/data/x_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after all the analysis, you can train your final model and put it here:\n",
    "model = BaggingClassifier()\n",
    "model.fit(x_train,y_train)\n",
    "pickle.dump(model, open(\"C://mlops_plugin//_deploy//model//model.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Head over to C:\\mlops_plugin\\_deploy\n",
    "# uvicorn main:app\n",
    "# this will start the model server at http://127.0.0.1:8000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
