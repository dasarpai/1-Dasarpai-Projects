{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Inpiration https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first neural network with keras tutorial\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('pima_indian_diabetes.csv', delimiter=',')\n",
    "\n",
    "# split into input (X) and output (y) variables\n",
    "X = dataset.iloc[:,0:7]\n",
    "y = dataset.iloc[:,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(13, input_dim=7, activation='relu'))\n",
    "model.add(Dense(9, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.frame.DataFrame, (313, 7), pandas.core.series.Series, (313,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train), X_train.shape, type(y_train), y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 313 entries, 258 to 102\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   No_Times_Pregnant  313 non-null    int64  \n",
      " 1   Plasma_Glucose     313 non-null    int64  \n",
      " 2   Diastolic_BP       313 non-null    int64  \n",
      " 3   Triceps            313 non-null    int64  \n",
      " 4   Insulin            313 non-null    int64  \n",
      " 5   BMI                313 non-null    float64\n",
      " 6   Age                313 non-null    int64  \n",
      "dtypes: float64(1), int64(6)\n",
      "memory usage: 19.6 KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 26.9903 - accuracy: 0.6709\n",
      "Epoch 2/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 13.1206 - accuracy: 0.6709\n",
      "Epoch 3/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 2.2429 - accuracy: 0.6102\n",
      "Epoch 4/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.9329 - accuracy: 0.6486\n",
      "Epoch 5/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.8202 - accuracy: 0.6390\n",
      "Epoch 6/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.6791 - accuracy: 0.6262\n",
      "Epoch 7/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.4807 - accuracy: 0.6358\n",
      "Epoch 8/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.4177 - accuracy: 0.6390\n",
      "Epoch 9/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2991 - accuracy: 0.6390\n",
      "Epoch 10/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.2351 - accuracy: 0.6709\n",
      "Epoch 11/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.1813 - accuracy: 0.6613\n",
      "Epoch 12/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.1558 - accuracy: 0.6390\n",
      "Epoch 13/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.0773 - accuracy: 0.6677\n",
      "Epoch 14/150\n",
      "32/32 [==============================] - 0s 937us/step - loss: 1.0503 - accuracy: 0.6805\n",
      "Epoch 15/150\n",
      "32/32 [==============================] - 0s 906us/step - loss: 1.0148 - accuracy: 0.6741\n",
      "Epoch 16/150\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.9745 - accuracy: 0.6709\n",
      "Epoch 17/150\n",
      "32/32 [==============================] - 0s 875us/step - loss: 0.9551 - accuracy: 0.6358\n",
      "Epoch 18/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9203 - accuracy: 0.6645\n",
      "Epoch 19/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8984 - accuracy: 0.6613\n",
      "Epoch 20/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.0200 - accuracy: 0.6550\n",
      "Epoch 21/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8695 - accuracy: 0.6486\n",
      "Epoch 22/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8531 - accuracy: 0.6773\n",
      "Epoch 23/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8426 - accuracy: 0.6709\n",
      "Epoch 24/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7845 - accuracy: 0.6773\n",
      "Epoch 25/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7996 - accuracy: 0.6709\n",
      "Epoch 26/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.8066 - accuracy: 0.6805\n",
      "Epoch 27/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7767 - accuracy: 0.6741\n",
      "Epoch 28/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7893 - accuracy: 0.6805\n",
      "Epoch 29/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7399 - accuracy: 0.6965\n",
      "Epoch 30/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6989 - accuracy: 0.6901\n",
      "Epoch 31/150\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.6881 - accuracy: 0.7061\n",
      "Epoch 32/150\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.6870 - accuracy: 0.6741\n",
      "Epoch 33/150\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.6858 - accuracy: 0.6869\n",
      "Epoch 34/150\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.6636 - accuracy: 0.6933\n",
      "Epoch 35/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6673 - accuracy: 0.6901\n",
      "Epoch 36/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6704 - accuracy: 0.6869\n",
      "Epoch 37/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6590 - accuracy: 0.6709\n",
      "Epoch 38/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6741 - accuracy: 0.7093\n",
      "Epoch 39/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6772 - accuracy: 0.6677\n",
      "Epoch 40/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6547 - accuracy: 0.7029\n",
      "Epoch 41/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.7097 - accuracy: 0.6677\n",
      "Epoch 42/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6353 - accuracy: 0.6997\n",
      "Epoch 43/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6241 - accuracy: 0.7157\n",
      "Epoch 44/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6098 - accuracy: 0.6965\n",
      "Epoch 45/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6182 - accuracy: 0.7252\n",
      "Epoch 46/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6242 - accuracy: 0.7093\n",
      "Epoch 47/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6006 - accuracy: 0.7188\n",
      "Epoch 48/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6751 - accuracy: 0.6869\n",
      "Epoch 49/150\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.6351 - accuracy: 0.6741\n",
      "Epoch 50/150\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.6011 - accuracy: 0.7284\n",
      "Epoch 51/150\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.5815 - accuracy: 0.7284\n",
      "Epoch 52/150\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.6011 - accuracy: 0.7188\n",
      "Epoch 53/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5729 - accuracy: 0.7125\n",
      "Epoch 54/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5799 - accuracy: 0.7252\n",
      "Epoch 55/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6193 - accuracy: 0.6550\n",
      "Epoch 56/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5802 - accuracy: 0.7093\n",
      "Epoch 57/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5672 - accuracy: 0.7029\n",
      "Epoch 58/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 0.7316\n",
      "Epoch 59/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7252\n",
      "Epoch 60/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5756 - accuracy: 0.7220\n",
      "Epoch 61/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5777 - accuracy: 0.7157\n",
      "Epoch 62/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6026 - accuracy: 0.7284\n",
      "Epoch 63/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6411 - accuracy: 0.6997\n",
      "Epoch 64/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5869 - accuracy: 0.7125\n",
      "Epoch 65/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5587 - accuracy: 0.7252\n",
      "Epoch 66/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5635 - accuracy: 0.7220\n",
      "Epoch 67/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6056 - accuracy: 0.7284\n",
      "Epoch 68/150\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 0.6498 - accuracy: 0.6645\n",
      "Epoch 69/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6569 - accuracy: 0.6965\n",
      "Epoch 70/150\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.5481 - accuracy: 0.7540\n",
      "Epoch 71/150\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.5591 - accuracy: 0.7125\n",
      "Epoch 72/150\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.5688 - accuracy: 0.7093\n",
      "Epoch 73/150\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.6210 - accuracy: 0.6933\n",
      "Epoch 74/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5664 - accuracy: 0.7380\n",
      "Epoch 75/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5807 - accuracy: 0.6901\n",
      "Epoch 76/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5965 - accuracy: 0.7125\n",
      "Epoch 77/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5586 - accuracy: 0.7188\n",
      "Epoch 78/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5456 - accuracy: 0.7348\n",
      "Epoch 79/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5578 - accuracy: 0.7188\n",
      "Epoch 80/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5498 - accuracy: 0.7220\n",
      "Epoch 81/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5502 - accuracy: 0.7093\n",
      "Epoch 82/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7220\n",
      "Epoch 83/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5306 - accuracy: 0.7700\n",
      "Epoch 84/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5819 - accuracy: 0.6901\n",
      "Epoch 85/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6091 - accuracy: 0.6933\n",
      "Epoch 86/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5858 - accuracy: 0.6965\n",
      "Epoch 87/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5761 - accuracy: 0.6869\n",
      "Epoch 88/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5469 - accuracy: 0.7316\n",
      "Epoch 89/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5493 - accuracy: 0.7125\n",
      "Epoch 90/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5894 - accuracy: 0.6997\n",
      "Epoch 91/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5408 - accuracy: 0.7380\n",
      "Epoch 92/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5732 - accuracy: 0.7188\n",
      "Epoch 93/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6157 - accuracy: 0.6965\n",
      "Epoch 94/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7508\n",
      "Epoch 95/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5757 - accuracy: 0.6965\n",
      "Epoch 96/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.7380\n",
      "Epoch 97/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5394 - accuracy: 0.7284\n",
      "Epoch 98/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5224 - accuracy: 0.7348\n",
      "Epoch 99/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7412\n",
      "Epoch 100/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5481 - accuracy: 0.7444\n",
      "Epoch 101/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5381 - accuracy: 0.7476\n",
      "Epoch 102/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5587 - accuracy: 0.7380\n",
      "Epoch 103/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5432 - accuracy: 0.7380\n",
      "Epoch 104/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5371 - accuracy: 0.7412\n",
      "Epoch 105/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5349 - accuracy: 0.7188\n",
      "Epoch 106/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7540\n",
      "Epoch 107/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5599 - accuracy: 0.7252\n",
      "Epoch 108/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5419 - accuracy: 0.7412\n",
      "Epoch 109/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5502 - accuracy: 0.7316\n",
      "Epoch 110/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5772 - accuracy: 0.7220\n",
      "Epoch 111/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5499 - accuracy: 0.7476\n",
      "Epoch 112/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5211 - accuracy: 0.7572\n",
      "Epoch 113/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5695 - accuracy: 0.6997\n",
      "Epoch 114/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.7348\n",
      "Epoch 115/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5344 - accuracy: 0.7444\n",
      "Epoch 116/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5217 - accuracy: 0.7508\n",
      "Epoch 117/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5170 - accuracy: 0.7444\n",
      "Epoch 118/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.7220\n",
      "Epoch 119/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5303 - accuracy: 0.7284\n",
      "Epoch 120/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5379 - accuracy: 0.7284\n",
      "Epoch 121/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5173 - accuracy: 0.7412\n",
      "Epoch 122/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5319 - accuracy: 0.7188\n",
      "Epoch 123/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5266 - accuracy: 0.7348\n",
      "Epoch 124/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5407 - accuracy: 0.7252\n",
      "Epoch 125/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5452 - accuracy: 0.7220\n",
      "Epoch 126/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5324 - accuracy: 0.7220\n",
      "Epoch 127/150\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.5861 - accuracy: 0.7093\n",
      "Epoch 128/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5283 - accuracy: 0.7220\n",
      "Epoch 129/150\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.5276 - accuracy: 0.7668\n",
      "Epoch 130/150\n",
      "32/32 [==============================] - 0s 938us/step - loss: 0.5036 - accuracy: 0.7508\n",
      "Epoch 131/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5164 - accuracy: 0.7316\n",
      "Epoch 132/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5327 - accuracy: 0.7380\n",
      "Epoch 133/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7540\n",
      "Epoch 134/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5123 - accuracy: 0.7284\n",
      "Epoch 135/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5158 - accuracy: 0.7604\n",
      "Epoch 136/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6036 - accuracy: 0.7125\n",
      "Epoch 137/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6176 - accuracy: 0.7157\n",
      "Epoch 138/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5108 - accuracy: 0.7444\n",
      "Epoch 139/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5449 - accuracy: 0.7348\n",
      "Epoch 140/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5253 - accuracy: 0.7444\n",
      "Epoch 141/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5711 - accuracy: 0.7348\n",
      "Epoch 142/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5210 - accuracy: 0.7412\n",
      "Epoch 143/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5027 - accuracy: 0.7508\n",
      "Epoch 144/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5204 - accuracy: 0.7540\n",
      "Epoch 145/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5386 - accuracy: 0.7412\n",
      "Epoch 146/150\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.7444\n",
      "Epoch 147/150\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.5231 - accuracy: 0.7412\n",
      "Epoch 148/150\n",
      "32/32 [==============================] - 0s 937us/step - loss: 0.5046 - accuracy: 0.7508\n",
      "Epoch 149/150\n",
      "32/32 [==============================] - 0s 1000us/step - loss: 0.5247 - accuracy: 0.7572\n",
      "Epoch 150/150\n",
      "32/32 [==============================] - 0s 906us/step - loss: 0.4941 - accuracy: 0.7668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26b6c048f40>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the keras model on the dataset\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Performance on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6034 - accuracy: 0.7595\n",
      "Accuracy: 75.95\n"
     ]
    }
   ],
   "source": [
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33886147 0\n",
      "0.21184516 0\n",
      "0.059678078 0\n",
      "0.6624281 1\n",
      "0.23439562 1\n",
      "0.47827694 0\n",
      "0.15899265 0\n",
      "0.21855217 0\n",
      "0.79835355 1\n",
      "0.34270412 0\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test[:10])\n",
    "for i in range(len(predictions)):\n",
    "   # make probability predictions with the model\n",
    "   \n",
    "    print (predictions[i][0], y_test.iloc[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model as JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "WARNING:tensorflow:5 out of the last 26 calls to <function Model.make_test_function.<locals>.test_function at 0x00000142126DDE50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "accuracy: 75.95%\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model as YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to YAML\n",
    "model_yaml = model.to_yaml()\n",
    "with open(\"model.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model from YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x0000014212FDD040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "accuracy: 75.95%\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_yaml\n",
    "\n",
    "# load YAML and create model\n",
    "yaml_file = open('model.yaml', 'r')\n",
    "loaded_model_yaml = yaml_file.read()\n",
    "yaml_file.close()\n",
    "loaded_model = model_from_yaml(loaded_model_yaml)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model and Architecture Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# save model and architecture to single file\n",
    "model.save(\"model_full.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model from Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 13)                104       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 9)                 126       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 240\n",
      "Trainable params: 240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x0000014214173A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "accuracy: 75.95%\n"
     ]
    }
   ],
   "source": [
    "# load and evaluate a saved model\n",
    "from keras.models import load_model\n",
    " \n",
    "# load model\n",
    "model = load_model('model_full.h5')\n",
    "# summarize model.\n",
    "model.summary()\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
