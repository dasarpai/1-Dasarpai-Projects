{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "df = pandas.read_csv(\"iris.csv\")\n",
    "X = df.iloc[:,0:4]\n",
    "y = df.iloc[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 5), (150, 4), (150,))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128    Iris-virginica\n",
       "102    Iris-virginica\n",
       "107    Iris-virginica\n",
       "9         Iris-setosa\n",
       "6         Iris-setosa\n",
       "Name: Species, dtype: object"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "\n",
    "encoded_y = encoder.transform(y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "y = np_utils.to_categorical(encoded_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#target variable is encoded\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Test Split\n",
    "X_train , X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define baseline model\n",
    "def baseline_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(8, input_dim=4, activation='relu'))\n",
    "\tmodel.add(Dense(3, activation='softmax'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=200, batch_size=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset is very small so lets use Kfold and Cross Validation for training\n",
    "kfold = KFold(n_splits=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002531DC6C3A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002531E65FA60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002531EA8A0D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002531FDC8700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x0000025320114D30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002532051B3A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002531FEB33A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002531FDC6E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002531E4034C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000002532063DAF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "#Train the model using Kfold corss validator\n",
    "results = cross_val_score(estimator, X_train, dummy_y_train, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 97.50% (3.82%)\n"
     ]
    }
   ],
   "source": [
    "#Let's check result of this training\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training without Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = baseline_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "12/12 [==============================] - 0s 998us/step - loss: 1.0028 - accuracy: 0.3750\n",
      "Epoch 2/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.9201 - accuracy: 0.6167\n",
      "Epoch 3/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.8621 - accuracy: 0.6917\n",
      "Epoch 4/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.8252 - accuracy: 0.6917\n",
      "Epoch 5/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.7790 - accuracy: 0.6917\n",
      "Epoch 6/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.7351 - accuracy: 0.6917\n",
      "Epoch 7/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.7128 - accuracy: 0.6917\n",
      "Epoch 8/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.6917\n",
      "Epoch 9/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.6799 - accuracy: 0.6917\n",
      "Epoch 10/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.6658 - accuracy: 0.6917\n",
      "Epoch 11/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.6517 - accuracy: 0.6917\n",
      "Epoch 12/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6385 - accuracy: 0.6917\n",
      "Epoch 13/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6265 - accuracy: 0.7167\n",
      "Epoch 14/150\n",
      "12/12 [==============================] - 0s 916us/step - loss: 0.6151 - accuracy: 0.7250\n",
      "Epoch 15/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6040 - accuracy: 0.7250\n",
      "Epoch 16/150\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 0.5944 - accuracy: 0.7333\n",
      "Epoch 17/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5843 - accuracy: 0.7333\n",
      "Epoch 18/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5748 - accuracy: 0.7583\n",
      "Epoch 19/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.7750\n",
      "Epoch 20/150\n",
      "12/12 [==============================] - 0s 916us/step - loss: 0.5574 - accuracy: 0.8000\n",
      "Epoch 21/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5489 - accuracy: 0.8167\n",
      "Epoch 22/150\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.5646 - accuracy: 0.80 - 0s 1ms/step - loss: 0.5408 - accuracy: 0.8250\n",
      "Epoch 23/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5329 - accuracy: 0.8250\n",
      "Epoch 24/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5253 - accuracy: 0.8250\n",
      "Epoch 25/150\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5191 - accuracy: 0.8250\n",
      "Epoch 26/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.8333\n",
      "Epoch 27/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5035 - accuracy: 0.8417\n",
      "Epoch 28/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4966 - accuracy: 0.8500\n",
      "Epoch 29/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4894 - accuracy: 0.8500\n",
      "Epoch 30/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.8417\n",
      "Epoch 31/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4765 - accuracy: 0.8417\n",
      "Epoch 32/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.8500\n",
      "Epoch 33/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4648 - accuracy: 0.8833\n",
      "Epoch 34/150\n",
      "12/12 [==============================] - 0s 915us/step - loss: 0.4583 - accuracy: 0.8833\n",
      "Epoch 35/150\n",
      "12/12 [==============================] - 0s 915us/step - loss: 0.4519 - accuracy: 0.8833\n",
      "Epoch 36/150\n",
      "12/12 [==============================] - 0s 917us/step - loss: 0.4462 - accuracy: 0.8833\n",
      "Epoch 37/150\n",
      "12/12 [==============================] - 0s 917us/step - loss: 0.4404 - accuracy: 0.8917\n",
      "Epoch 38/150\n",
      "12/12 [==============================] - 0s 917us/step - loss: 0.4351 - accuracy: 0.8917\n",
      "Epoch 39/150\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 0.4299 - accuracy: 0.9083\n",
      "Epoch 40/150\n",
      "12/12 [==============================] - 0s 917us/step - loss: 0.4240 - accuracy: 0.9167\n",
      "Epoch 41/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4193 - accuracy: 0.9167\n",
      "Epoch 42/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4140 - accuracy: 0.9167\n",
      "Epoch 43/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4089 - accuracy: 0.9167\n",
      "Epoch 44/150\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 0.4042 - accuracy: 0.9167\n",
      "Epoch 45/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.3988 - accuracy: 0.9250\n",
      "Epoch 46/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.3945 - accuracy: 0.9250\n",
      "Epoch 47/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.3893 - accuracy: 0.9250\n",
      "Epoch 48/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3845 - accuracy: 0.9333\n",
      "Epoch 49/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.3802 - accuracy: 0.9500\n",
      "Epoch 50/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3754 - accuracy: 0.9417\n",
      "Epoch 51/150\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 0.3717 - accuracy: 0.9500\n",
      "Epoch 52/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.9583\n",
      "Epoch 53/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.3620 - accuracy: 0.9500\n",
      "Epoch 54/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3589 - accuracy: 0.9500\n",
      "Epoch 55/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3564 - accuracy: 0.9500\n",
      "Epoch 56/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.3498 - accuracy: 0.9500\n",
      "Epoch 57/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3460 - accuracy: 0.9500\n",
      "Epoch 58/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3420 - accuracy: 0.9500\n",
      "Epoch 59/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.3384 - accuracy: 0.9583\n",
      "Epoch 60/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3344 - accuracy: 0.9583\n",
      "Epoch 61/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3315 - accuracy: 0.9500\n",
      "Epoch 62/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.9583\n",
      "Epoch 63/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3250 - accuracy: 0.9583\n",
      "Epoch 64/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3197 - accuracy: 0.9500\n",
      "Epoch 65/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3183 - accuracy: 0.9667\n",
      "Epoch 66/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3124 - accuracy: 0.9667\n",
      "Epoch 67/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.9500\n",
      "Epoch 68/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3068 - accuracy: 0.9583\n",
      "Epoch 69/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3026 - accuracy: 0.9667\n",
      "Epoch 70/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2989 - accuracy: 0.9583\n",
      "Epoch 71/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2964 - accuracy: 0.9667\n",
      "Epoch 72/150\n",
      "12/12 [==============================] - 0s 834us/step - loss: 0.2925 - accuracy: 0.9667\n",
      "Epoch 73/150\n",
      "12/12 [==============================] - 0s 833us/step - loss: 0.2897 - accuracy: 0.9667\n",
      "Epoch 74/150\n",
      "12/12 [==============================] - 0s 917us/step - loss: 0.2860 - accuracy: 0.9667\n",
      "Epoch 75/150\n",
      "12/12 [==============================] - 0s 833us/step - loss: 0.2834 - accuracy: 0.9667\n",
      "Epoch 76/150\n",
      "12/12 [==============================] - 0s 918us/step - loss: 0.2804 - accuracy: 0.9667\n",
      "Epoch 77/150\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.2774 - accuracy: 0.9667\n",
      "Epoch 78/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2742 - accuracy: 0.9667\n",
      "Epoch 79/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2716 - accuracy: 0.9667\n",
      "Epoch 80/150\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2684 - accuracy: 0.9667\n",
      "Epoch 81/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2660 - accuracy: 0.9667\n",
      "Epoch 82/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2637 - accuracy: 0.9667\n",
      "Epoch 83/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2605 - accuracy: 0.9667\n",
      "Epoch 84/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2574 - accuracy: 0.9667\n",
      "Epoch 85/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2554 - accuracy: 0.9667\n",
      "Epoch 86/150\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2522 - accuracy: 0.9667\n",
      "Epoch 87/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2510 - accuracy: 0.9667\n",
      "Epoch 88/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2473 - accuracy: 0.9667\n",
      "Epoch 89/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2447 - accuracy: 0.9667\n",
      "Epoch 90/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2424 - accuracy: 0.9667\n",
      "Epoch 91/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2409 - accuracy: 0.9667\n",
      "Epoch 92/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2393 - accuracy: 0.9667\n",
      "Epoch 93/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2350 - accuracy: 0.9667\n",
      "Epoch 94/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2354 - accuracy: 0.9583\n",
      "Epoch 95/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2315 - accuracy: 0.9667\n",
      "Epoch 96/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2285 - accuracy: 0.9750\n",
      "Epoch 97/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2273 - accuracy: 0.9667\n",
      "Epoch 98/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2240 - accuracy: 0.9667\n",
      "Epoch 99/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2226 - accuracy: 0.9667\n",
      "Epoch 100/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2201 - accuracy: 0.9667\n",
      "Epoch 101/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2190 - accuracy: 0.9667\n",
      "Epoch 102/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2158 - accuracy: 0.9667\n",
      "Epoch 103/150\n",
      "12/12 [==============================] - 0s 917us/step - loss: 0.2141 - accuracy: 0.9667\n",
      "Epoch 104/150\n",
      "12/12 [==============================] - 0s 917us/step - loss: 0.2131 - accuracy: 0.9667\n",
      "Epoch 105/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2106 - accuracy: 0.9667\n",
      "Epoch 106/150\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 0.2080 - accuracy: 0.9667\n",
      "Epoch 107/150\n",
      "12/12 [==============================] - 0s 916us/step - loss: 0.2066 - accuracy: 0.9750\n",
      "Epoch 108/150\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 0.2044 - accuracy: 0.9667\n",
      "Epoch 109/150\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 0.2030 - accuracy: 0.9667\n",
      "Epoch 110/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2023 - accuracy: 0.9667\n",
      "Epoch 111/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2006 - accuracy: 0.9583\n",
      "Epoch 112/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1982 - accuracy: 0.9667\n",
      "Epoch 113/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1960 - accuracy: 0.9667\n",
      "Epoch 114/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1943 - accuracy: 0.9667\n",
      "Epoch 115/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1924 - accuracy: 0.9667\n",
      "Epoch 116/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1914 - accuracy: 0.9667\n",
      "Epoch 117/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1894 - accuracy: 0.9667\n",
      "Epoch 118/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1888 - accuracy: 0.9750\n",
      "Epoch 119/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1889 - accuracy: 0.9750\n",
      "Epoch 120/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1852 - accuracy: 0.9667\n",
      "Epoch 121/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1834 - accuracy: 0.9667\n",
      "Epoch 122/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1831 - accuracy: 0.9667\n",
      "Epoch 123/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1811 - accuracy: 0.9667\n",
      "Epoch 124/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.9667\n",
      "Epoch 125/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.9833\n",
      "Epoch 126/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1763 - accuracy: 0.9750\n",
      "Epoch 127/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1760 - accuracy: 0.9667\n",
      "Epoch 128/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1744 - accuracy: 0.9667\n",
      "Epoch 129/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1724 - accuracy: 0.9750\n",
      "Epoch 130/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1712 - accuracy: 0.9750\n",
      "Epoch 131/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1701 - accuracy: 0.9750\n",
      "Epoch 132/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1690 - accuracy: 0.9750\n",
      "Epoch 133/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1677 - accuracy: 0.9667\n",
      "Epoch 134/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1677 - accuracy: 0.9750\n",
      "Epoch 135/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1649 - accuracy: 0.9833\n",
      "Epoch 136/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1638 - accuracy: 0.9667\n",
      "Epoch 137/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1631 - accuracy: 0.9667\n",
      "Epoch 138/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1616 - accuracy: 0.9750\n",
      "Epoch 139/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1609 - accuracy: 0.9750\n",
      "Epoch 140/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1595 - accuracy: 0.9833\n",
      "Epoch 141/150\n",
      "12/12 [==============================] - 0s 999us/step - loss: 0.1583 - accuracy: 0.9667\n",
      "Epoch 142/150\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 0.1575 - accuracy: 0.9750\n",
      "Epoch 143/150\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 0.1563 - accuracy: 0.9750\n",
      "Epoch 144/150\n",
      "12/12 [==============================] - 0s 917us/step - loss: 0.1551 - accuracy: 0.9750\n",
      "Epoch 145/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1543 - accuracy: 0.9750\n",
      "Epoch 146/150\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1537 - accuracy: 0.9667\n",
      "Epoch 147/150\n",
      "12/12 [==============================] - 0s 999us/step - loss: 0.1525 - accuracy: 0.9750\n",
      "Epoch 148/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1517 - accuracy: 0.9667\n",
      "Epoch 149/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1499 - accuracy: 0.9750\n",
      "Epoch 150/150\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1507 - accuracy: 0.9750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x253200b6970>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, y_train, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction on Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1.] [0. 0. 1.]\n",
      "[0.  0.9 0.1] [0. 1. 0.]\n",
      "[1. 0. 0.] [1. 0. 0.]\n",
      "[0.  0.1 0.9] [0. 0. 1.]\n",
      "[1. 0. 0.] [1. 0. 0.]\n",
      "[0. 0. 1.] [0. 0. 1.]\n",
      "[1. 0. 0.] [1. 0. 0.]\n",
      "[0.  0.9 0.1] [0. 1. 0.]\n",
      "[0.  0.8 0.1] [0. 1. 0.]\n",
      "[0.  0.9 0.1] [0. 1. 0.]\n",
      "[0.  0.2 0.8] [0. 0. 1.]\n",
      "[0.  0.9 0.1] [0. 1. 0.]\n",
      "[0.  0.8 0.2] [0. 1. 0.]\n",
      "[0.  0.8 0.2] [0. 1. 0.]\n",
      "[0.  0.7 0.3] [0. 1. 0.]\n",
      "[1. 0. 0.] [1. 0. 0.]\n",
      "[0.  0.7 0.3] [0. 1. 0.]\n",
      "[0.  0.7 0.3] [0. 1. 0.]\n",
      "[1. 0. 0.] [1. 0. 0.]\n",
      "[1. 0. 0.] [1. 0. 0.]\n",
      "[0.  0.1 0.9] [0. 0. 1.]\n",
      "[0.  0.6 0.4] [0. 1. 0.]\n",
      "[1. 0. 0.] [1. 0. 0.]\n",
      "[1. 0. 0.] [1. 0. 0.]\n",
      "[0.  0.3 0.7] [0. 0. 1.]\n",
      "[1. 0. 0.] [1. 0. 0.]\n",
      "[1. 0. 0.] [1. 0. 0.]\n",
      "[0.  0.9 0.1] [0. 1. 0.]\n",
      "[0.1 0.9 0. ] [0. 1. 0.]\n",
      "[1. 0. 0.] [1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "y_pred_f=[]\n",
    "y_test_f=[]\n",
    "for i in range( len(y_pred)):\n",
    "    print ( np.round(y_pred[i],1), y_test[i])\n",
    "    #print (  np.argmax(y_pred[i]), np.argmax(y_test[i]) )\n",
    "    y_pred_f.append(np.argmax(y_pred[i]))\n",
    "    y_test_f.append(np.argmax(y_test[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics \n",
    "metrics.accuracy_score(y_test_f,y_pred_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (metrics.classification_report(y_test_f, y_pred_f))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
